{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c36bf832-f27d-4e6a-ba7a-03f2a2d8534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.functional import F\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision.ops import nms\n",
    "from torchvision.ops import RoIPool\n",
    "\n",
    "from torchvision.ops import boxes as box_ops\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import cv2\n",
    "\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b967ef-7e73-4269-8c0b-55ac7c742791",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device('cuda:4' if use_cuda else 'cpu')\n",
    "x = torch.Tensor([0]).cuda(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10964da-7526-4058-a5e2-ab559afc3eb8",
   "metadata": {},
   "source": [
    "# 数据集读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8198391a-99d9-40a2-90ce-ff7ae99c617d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = 'data/SAR_Airplane_Recognition_trainData/trainData/'\n",
    "image_path = path + 'Images/'\n",
    "gt_path = path + 'gt/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f9d57de-3bf8-40ae-a9f9-7e46d28b89ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsexml(gt_path, filename):\n",
    "    gt_filename = gt_path + filename\n",
    "    gt_sample = ET.parse(gt_filename)\n",
    "\n",
    "    img_filename = gt_sample.find('source').find('filename').text\n",
    "\n",
    "    Objects = gt_sample.find('objects').findall('object')\n",
    "    objects_name = []\n",
    "    bboxes = []\n",
    "    for object in Objects:\n",
    "        object_name = object.find('possibleresult').find('name').text\n",
    "        objects_name.append(object_name)\n",
    "        points = object.find('points').findall('point')\n",
    "        xmin,ymin = points[0].text.split(',')\n",
    "        xmax,ymax = points[2].text.split(',')\n",
    "        bbox = [int(float(xmin)), int(float(ymin)), int(float(xmax)), int(float(ymax))]\n",
    "        bboxes.append(torch.Tensor(bbox))\n",
    "    cls_dict = { 'A220':0,\n",
    "                 'A330':1, \n",
    "                 'A320/321':2, \n",
    "                 'Boeing737-800':3,\n",
    "                 'Boeing787':4,\n",
    "                 'ARJ21':5, \n",
    "                 'other':6}\n",
    "    target = {\n",
    "                'filename':img_filename,\n",
    "                'labels':[cls_dict[i] for i in objects_name],\n",
    "                'boxes':bboxes\n",
    "            }\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9f8b6eb-42f3-4085-b450-81dac01ab54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': '2.tif',\n",
       " 'labels': [6, 0, 6, 5, 6],\n",
       " 'boxes': [tensor([147., 105., 239., 173.]),\n",
       "  tensor([145.,   1., 252.,  73.]),\n",
       "  tensor([157., 228., 239., 293.]),\n",
       "  tensor([242., 879., 307., 936.]),\n",
       "  tensor([312., 882., 383., 934.])]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsexml(gt_path,'2.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94877001-f115-46c6-8b51-fe446ef7b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dir = sorted([i for i in os.listdir(gt_path) if i[-3:] == 'xml'])\n",
    "targets = []\n",
    "for filename in gt_dir:\n",
    "    targets.append(parsexml(gt_path,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "958ca43e-f15b-4278-9af3-ead408400840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': '1409.tif',\n",
       " 'labels': [4, 4],\n",
       " 'boxes': [tensor([  1., 398., 119., 532.]), tensor([ 10., 232., 114., 331.])]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[456]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "391990fd-aad7-432b-957e-3be44b2e545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs = []\n",
    "# for target in tqdm(targets, desc = 'Load data'):\n",
    "#     filename = target['filename']\n",
    "#     img = cv2.imread(image_path + filename)\n",
    "#     img = torch.from_numpy(img)\n",
    "#     imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddd03b64-fc73-42e2-b795-f4048445aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAR_dset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path = 'data/SAR_Airplane_Recognition_trainData/trainData/'):\n",
    "        super(SAR_dset, self).__init__()\n",
    "        self.image_path = path + 'Images/'\n",
    "        self.gt_path = path + 'gt/'\n",
    "        self.gt_dir = sorted([i for i in os.listdir(self.gt_path) if i[-3:] == 'xml'])\n",
    "        self.targets = []\n",
    "        for filename in  self.gt_dir:\n",
    "            self.targets.append(self.parsexml(gt_path,filename))\n",
    "        \n",
    "        self.imgs = []\n",
    "        for target in tqdm(self.targets, desc = 'Load data'):\n",
    "            filename = target['filename']\n",
    "            img = cv2.imread(self.image_path + filename)\n",
    "            img = torch.from_numpy(img).permute(2,0,1)/255\n",
    "            self.imgs.append(img)\n",
    "        \n",
    "        self.train_img = self.imgs[:1000]\n",
    "        self.train_targets = self.targets[:1000]\n",
    "        \n",
    "        self.test_img = self.imgs[1000:]\n",
    "        self.test_targets = self.targets[1000:]\n",
    "        self.mode = 'train'\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'train':\n",
    "            return self.train_img[index],self.train_targets[index]\n",
    "        else:\n",
    "            return self.test_img[index],self.test_targets[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.mode == 'train':\n",
    "            return len(self.train_img)\n",
    "        else:\n",
    "            len(self.test_img)\n",
    "    \n",
    "\n",
    "        \n",
    "    def parsexml(self, gt_path, filename):\n",
    "        gt_filename = gt_path + filename\n",
    "        gt_sample = ET.parse(gt_filename)\n",
    "\n",
    "        img_filename = gt_sample.find('source').find('filename').text\n",
    "\n",
    "        Objects = gt_sample.find('objects').findall('object')\n",
    "        objects_name = []\n",
    "        bboxes = []\n",
    "        for object in Objects:\n",
    "            object_name = object.find('possibleresult').find('name').text\n",
    "            objects_name.append(object_name)\n",
    "            points = object.find('points').findall('point')\n",
    "            xmin,ymin = points[0].text.split(',')\n",
    "            xmax,ymax = points[2].text.split(',')\n",
    "            bbox = [int(float(xmin)), int(float(ymin)), int(float(xmax)), int(float(ymax))]\n",
    "            bboxes.append(torch.Tensor(bbox))\n",
    "        cls_dict = { 'A220':0,\n",
    "                     'A330':1, \n",
    "                     'A320/321':2, \n",
    "                     'Boeing737-800':3,\n",
    "                     'Boeing787':4,\n",
    "                     'ARJ21':5, \n",
    "                     'other':6}\n",
    "        target = {\n",
    "                    'filename':img_filename,\n",
    "                    'labels':[cls_dict[i] for i in objects_name],\n",
    "                    'boxes':bboxes\n",
    "                }\n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c69c4623-fa56-4c5e-9240-8edc92417fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be8e9de07e24e4aa506918c2c6034c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load data:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sar_dset = SAR_dset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95901e03-2314-4421-840b-8cf295af242b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': '19.tif',\n",
       " 'labels': [4, 4, 4],\n",
       " 'boxes': [tensor([208., 544., 292., 599.]),\n",
       "  tensor([326., 538., 391., 599.]),\n",
       "  tensor([ 89., 557., 161., 599.])]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sar_dset.test_targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5e32ad1-da20-4b3e-a93f-d1a29481fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect(batch):\n",
    "#     print(batch)\n",
    "    img,target = [item for item in zip(*batch)]\n",
    "    for i in range(len(target)):\n",
    "        if isinstance(target[i]['boxes'],list):\n",
    "            target[i]['boxes'] = torch.stack(target[i]['boxes'],dim = 0)\n",
    "            target[i]['labels'] = torch.from_numpy(np.array(target[i]['labels'],dtype = np.int64))\n",
    "    return img,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad24c6fb-e67c-490d-9723-2c85b014e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_dataloader = torch.utils.data.DataLoader(sar_dset, batch_size = 8, shuffle = True,collate_fn = collect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6872f290-142e-4771-866f-5eec56fb0333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89e7a0f0c72432584bf81a6ecad8a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x,y in tqdm(sar_dataloader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b2c80-ad93-4157-a392-c0ca60bc678d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd1a9de1-9c12-4973-a9f3-dc18d1e04db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = torchvision.models.resnet50(pretrained = True)\n",
    "'''\n",
    "    特征提取网络，不使用FPN\n",
    "'''\n",
    "features_list = [\n",
    "                    resnet_model.conv1,\n",
    "                    resnet_model.bn1,\n",
    "                    resnet_model.relu,\n",
    "                    resnet_model.maxpool,\n",
    "                    resnet_model.layer1,\n",
    "                    resnet_model.layer2,\n",
    "                    resnet_model.layer3,\n",
    "                ]\n",
    "backbone = nn.Sequential(*features_list)\n",
    "backbone.out_channels = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67e4a72f-b09e-45f4-a2ec-208698e95658",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'filename': '1797.tif',\n",
       "  'labels': tensor([0, 6], device='cuda:4'),\n",
       "  'boxes': tensor([[ 29., 175., 108., 249.],\n",
       "          [ 34., 455., 182., 587.]], device='cuda:4')},\n",
       " {'filename': '1640.tif',\n",
       "  'labels': tensor([0], device='cuda:4'),\n",
       "  'boxes': tensor([[445., 811., 545., 890.]], device='cuda:4')},\n",
       " {'filename': '1308.tif',\n",
       "  'labels': tensor([0], device='cuda:4'),\n",
       "  'boxes': tensor([[781., 372., 880., 452.]], device='cuda:4')},\n",
       " {'filename': '1898.tif',\n",
       "  'labels': tensor([4, 6], device='cuda:4'),\n",
       "  'boxes': tensor([[585., 646., 738., 758.],\n",
       "          [847., 184., 989., 314.]], device='cuda:4')},\n",
       " {'filename': '1191.tif',\n",
       "  'labels': tensor([4, 6, 4, 6], device='cuda:4'),\n",
       "  'boxes': tensor([[ 945.,  936., 1023., 1023.],\n",
       "          [ 639.,  749.,  697.,  803.],\n",
       "          [ 928.,  780., 1023.,  864.],\n",
       "          [ 933.,  661., 1016.,  728.]], device='cuda:4')},\n",
       " {'filename': '1144.tif',\n",
       "  'labels': tensor([6, 4], device='cuda:4'),\n",
       "  'boxes': tensor([[461., 294., 599., 422.],\n",
       "          [459.,  36., 559., 134.]], device='cuda:4')},\n",
       " {'filename': '120.tif',\n",
       "  'labels': tensor([6], device='cuda:4'),\n",
       "  'boxes': tensor([[1.0000e+00, 1.2240e+03, 8.0000e+01, 1.3710e+03]], device='cuda:4')},\n",
       " {'filename': '1577.tif',\n",
       "  'labels': tensor([4, 0], device='cuda:4'),\n",
       "  'boxes': tensor([[188., 138., 258., 197.],\n",
       "          [121., 439., 187., 512.]], device='cuda:4')})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n",
    "                                                output_size=14,\n",
    "                                                sampling_ratio=2)\n",
    "anchor_generator = torchvision.models.detection.rpn.AnchorGenerator( sizes=((16, 32, 64, 128, 256, 512),),\n",
    "                                    aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "faster_rcnn = torchvision.models.detection.FasterRCNN(backbone,\n",
    "                                        num_classes = 7,\n",
    "                                        min_size = 200,\n",
    "                                        max_size = 5000,\n",
    "                                        rpn_anchor_generator=anchor_generator,\n",
    "                                        box_roi_pool=roi_pooler)\n",
    "faster_rcnn.to(device)\n",
    "x = [i.cuda(device) for i in x]\n",
    "for i in range(len(y)):\n",
    "    y[i]['labels'] = y[i]['labels'].cuda(device)\n",
    "    y[i]['boxes'] = y[i]['boxes'].cuda(device)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a051442-403c-4ad1-8d9e-72c0f1c0ffc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_classifier': tensor(1.9586, device='cuda:4', grad_fn=<NllLossBackward>),\n",
       " 'loss_box_reg': tensor(0.0178, device='cuda:4', grad_fn=<DivBackward0>),\n",
       " 'loss_objectness': tensor(0.6917, device='cuda:4', grad_fn=<BinaryCrossEntropyWithLogitsBackward>),\n",
       " 'loss_rpn_box_reg': tensor(0.0049, device='cuda:4', grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faster_rcnn(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d43783bc-9219-40b4-9e1f-99f850c1f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(faster_rcnn.parameters(), 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60535ee9-2e17-4472-84ba-ce9dee8bd680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eeedaec697b4fbabbf3d353fdf22df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482746fb54c747a9962f95bde8b95026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ab3fae424349b49b8ec20eed561d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b4b446c1d141dd82274cbcf09edd64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423113999c954c26aa1f7d2a7e8360c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42d1b2b748e48cf8d9e313d901abd52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55761320f49e4ad78659a7bcac2e5597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f5a33dd5af41a9864b4482843a5885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48a9c4a7037430b90f84e00edbe96a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b88509c091645c0b08584bf69b7bb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d34e70e699342c882c2e6c0c3c66f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "faster_rcnn.train()\n",
    "Epoch = 10\n",
    "min_loss = 123000000\n",
    "for epoch in trange(Epoch,desc = 'Epoch'):\n",
    "    myiter = tqdm(sar_dataloader,colour = '#0066FF')\n",
    "    myiter.set_description_str('Training')\n",
    "    loss1 = 0\n",
    "    for x,y in myiter:\n",
    "        x = [i.cuda(device) for i in x]\n",
    "        for i in range(len(y)):\n",
    "            y[i]['labels'] = y[i]['labels'].cuda(device)\n",
    "            y[i]['boxes'] = y[i]['boxes'].cuda(device)\n",
    "        \n",
    "        loss_dict = faster_rcnn(x,y)\n",
    "        loss = sum(loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        myiter.set_postfix(loss = float(loss),epoch = epoch, loss_all = loss1)\n",
    "        loss1 += float(loss)\n",
    "    if loss1 < min_loss:\n",
    "        min_loss = loss1\n",
    "        torch.save(faster_rcnn,'model/competition1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5784e5-c923-4bb3-a560-7b509abff5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9c423e-292f-48d0-a73e-8797724e3a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb772bc8-c770-40ab-8ce2-5a686a1264d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
