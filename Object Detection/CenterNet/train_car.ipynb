{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7445265f-8062-42c4-9356-455fb80a1530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.functional import F\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision.ops import nms\n",
    "from torchvision.ops import RoIPool\n",
    "\n",
    "from torchvision.ops import boxes as box_ops\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import cv2\n",
    "\n",
    "from model import CenterNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d970f957-0cbc-4d7e-b921-ed2e24c5738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device('cuda:4' if use_cuda else 'cpu')\n",
    "x = torch.Tensor([0]).cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd1f1b6e-888b-42fc-a832-bcf5f9f4da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset的路径\n",
    "path = '../data/car-object-detection/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc5dbc1f-3e8c-43d5-8053-77b46ed1e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    image file name: array([bbox1,bbox2])\n",
    "'''\n",
    "train_bbox_pd = pd.read_csv(path + 'train_solution_bounding_boxes.csv')\n",
    "train_bbox_np = train_bbox_pd.to_numpy()\n",
    "train_bbox = {}\n",
    "for d in train_bbox_np:\n",
    "    if d[0] not in train_bbox:\n",
    "        train_bbox.update({d[0]:[d[1:]]})\n",
    "    else:\n",
    "        train_bbox[d[0]].append(d[1:])\n",
    "train_bbox = {d:np.array(train_bbox[d]) for d in train_bbox}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b4e4581-07c4-4c72-a844-33b36b37e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset的路径\n",
    "path = '../data/car-object-detection/data/'\n",
    "train_imagefile = [i for i in os.listdir(path + 'training_images') if i[-3:] == 'jpg']\n",
    "test_imagefile = [i for i in os.listdir(path + 'testing_images') if i[-3:] == 'jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60865b91-c498-4566-a810-998bcb66cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cardset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path = '../data/car-object-detection/data/'):\n",
    "        super(cardset, self).__init__()\n",
    "        self.path = path\n",
    "        # 读取图像文件名\n",
    "        self.train_imagefile = [i for i in os.listdir(path + 'training_images') if i[-3:] == 'jpg']\n",
    "        self.test_imagefile = [i for i in os.listdir(path + 'testing_images') if i[-3:] == 'jpg']\n",
    "        self.train_img = []\n",
    "        self.test_img = []\n",
    "        # 读取训练集的bbox\n",
    "        train_bbox_pd = pd.read_csv(self.path + 'train_solution_bounding_boxes.csv')\n",
    "        self.train_bbox_np = train_bbox_pd.to_numpy()\n",
    "        self.train_bbox = {}\n",
    "        self.idx2file = {}\n",
    "        self.file2idx = {}\n",
    "        i = 0\n",
    "        for d in self.train_bbox_np:\n",
    "            if d[0] not in self.train_bbox:\n",
    "                self.train_bbox.update({d[0]:[d[1:]]})\n",
    "                self.idx2file.update({i:d[0]})\n",
    "                self.file2idx.update({d[0]:i})\n",
    "                i += 1\n",
    "            else:\n",
    "                self.train_bbox[d[0]].append(d[1:])\n",
    "        self.train_bbox = {d:np.array(self.train_bbox[d],dtype = np.float32) for d in self.train_bbox}\n",
    "        # 读取数据到内存\n",
    "        for filename in tqdm(self.train_imagefile,desc = 'Reading train data'):\n",
    "            img = Image.open(path + 'training_images/' + filename)\n",
    "            self.train_img.append([filename,img])\n",
    "            if filename not in self.train_bbox:\n",
    "                self.train_bbox.update({filename:[]})\n",
    "                self.idx2file.update({i:filename})\n",
    "                self.file2idx.update({filename:i})\n",
    "                i += 1\n",
    "                \n",
    "        for filename in tqdm(self.test_imagefile,desc = 'Reading test data'):\n",
    "            img = Image.open(path + 'testing_images/' + filename)\n",
    "            self.test_img.append([filename,img])\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(self.train_img[index][1],(Image.Image)):\n",
    "            self.train_img[index][1] = torchvision.transforms.functional.pil_to_tensor(self.train_img[index][1])/255\n",
    "        img = self.train_img[index][1]\n",
    "#         print(self.train_bbox[self.train_img[index][0]])\n",
    "        label_num = self.file2idx[self.train_img[index][0]]\n",
    "        return img, label_num\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd8d07c-8ffc-49ee-80b7-16d2de9ba422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb264c8edd46428880eca33478a11fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading train data:   0%|          | 0/1001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6b96d0a13647a68c29de36d3728048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading test data:   0%|          | 0/175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "car = cardset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73d86c85-bec1-42bf-afb7-2cf23915f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect(batch):\n",
    "    img,label_num = [i for i in zip(*batch)]\n",
    "    img = torch.stack(img,0)\n",
    "    label_num = torch.Tensor(label_num)\n",
    "    return img,label_num\n",
    "car_dataloader = torch.utils.data.DataLoader(car, batch_size = 8, shuffle = True,collate_fn = collect,drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0db4d875-f202-477f-8455-b389ac71d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myiter = tqdm(car_dataloader,colour = '#0066FF')\n",
    "# myiter.set_description_str('car dataloader')\n",
    "# for x,y in myiter:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a5b043e-8397-441a-90cc-3b032f6673d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTarget(x,y):\n",
    "    target = []\n",
    "    for i in y:\n",
    "        t = car.train_bbox[car.idx2file[int(i)]]\n",
    "        shape = len(t)\n",
    "        label = 1\n",
    "        if len(t) == 0:\n",
    "            t = [[0,0,x.shape[-1]-1,x.shape[-2]-1]]\n",
    "            shape = 1\n",
    "            label = 0\n",
    "        target.append({'bboxes':torch.Tensor(t).cuda(device), 'classes': torch.from_numpy(np.zeros(shape, dtype = np.int64) + label).cuda(device)})\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f296963-58fb-426a-a447-b67d88a942db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = getTarget(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ae236-2679-4cfa-b891-5d65ebfc23ba",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a8547ca-a211-4abf-97f1-7944c5f14b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centerNet = CenterNet(2)\n",
    "centerNet.to(device)\n",
    "centerNet.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa54fc6b-1eda-4ef6-98ab-da46ba2ddd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0131d115-dd8d-4aac-b859-91acd24ed936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result, losses = centerNet(x,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45453b25-8ad6-4732-9693-284dff1e2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(centerNet.parameters(),0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a97c25c-08c8-483f-b31e-182a55749a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad1572403404f38b390837b0197548d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-2ef45fbc4b58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'point_focal_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'offset_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     myiter.set_postfix(loss = float(loss),focal_loss = float(losses['point_focal_loss']),\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "myiter = tqdm(car_dataloader,colour = '#0066FF')\n",
    "myiter.set_description_str('car dataloader')\n",
    "centerNet.train()\n",
    "centerNet.mode = 'train'\n",
    "for x,y in myiter:\n",
    "    x = x.cuda(device)\n",
    "    target = getTarget(x,y)\n",
    "    result, losses = centerNet(x,target)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = losses['point_focal_loss'] + 0.1*losses['size_loss'] + losses['offset_loss']\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    myiter.set_postfix(loss = float(loss),focal_loss = float(losses['point_focal_loss']),\n",
    "                       size_loss = float(losses['size_loss']),\n",
    "                       offset_loss = float(losses['offset_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42ac662a-caa2-49dd-b3a3-5b3faee8e5d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   0.],\n",
       "        [  0.,  12.],\n",
       "        [  0.,  20.],\n",
       "        ...,\n",
       "        [380., 676.],\n",
       "        [380., 676.],\n",
       "        [380., 676.]], device='cuda:4', grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]['bboxes'][:,[1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e9513f-471b-419a-805a-88ab01dda83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc41ed1-c0a8-4f71-b2c3-a09d3c09dbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f018e28-d653-4b36-bda1-831c72177451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee4e50-fa9a-4195-905a-761010ad2896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
