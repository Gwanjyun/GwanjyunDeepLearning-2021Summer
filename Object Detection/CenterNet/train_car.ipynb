{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7445265f-8062-42c4-9356-455fb80a1530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.functional import F\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision.ops import nms\n",
    "from torchvision.ops import RoIPool\n",
    "\n",
    "from torchvision.ops import boxes as box_ops\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import cv2\n",
    "\n",
    "from model import CenterNet\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d970f957-0cbc-4d7e-b921-ed2e24c5738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device('cuda:4' if use_cuda else 'cpu')\n",
    "x = torch.Tensor([0]).cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd1f1b6e-888b-42fc-a832-bcf5f9f4da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset的路径\n",
    "path = '../data/car-object-detection/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc5dbc1f-3e8c-43d5-8053-77b46ed1e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    image file name: array([bbox1,bbox2])\n",
    "'''\n",
    "train_bbox_pd = pd.read_csv(path + 'train_solution_bounding_boxes.csv')\n",
    "train_bbox_np = train_bbox_pd.to_numpy()\n",
    "train_bbox = {}\n",
    "for d in train_bbox_np:\n",
    "    if d[0] not in train_bbox:\n",
    "        train_bbox.update({d[0]:[d[1:]]})\n",
    "    else:\n",
    "        train_bbox[d[0]].append(d[1:])\n",
    "train_bbox = {d:np.array(train_bbox[d]) for d in train_bbox}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b4e4581-07c4-4c72-a844-33b36b37e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset的路径\n",
    "path = '../data/car-object-detection/data/'\n",
    "train_imagefile = [i for i in os.listdir(path + 'training_images') if i[-3:] == 'jpg']\n",
    "test_imagefile = [i for i in os.listdir(path + 'testing_images') if i[-3:] == 'jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60865b91-c498-4566-a810-998bcb66cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cardset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path = '../data/car-object-detection/data/'):\n",
    "        super(cardset, self).__init__()\n",
    "        self.path = path\n",
    "        # 读取图像文件名\n",
    "        self.train_imagefile = [i for i in os.listdir(path + 'training_images') if i[-3:] == 'jpg']\n",
    "        self.test_imagefile = [i for i in os.listdir(path + 'testing_images') if i[-3:] == 'jpg']\n",
    "        self.train_img = []\n",
    "        self.test_img = []\n",
    "        # 读取训练集的bbox\n",
    "        train_bbox_pd = pd.read_csv(self.path + 'train_solution_bounding_boxes.csv')\n",
    "        self.train_bbox_np = train_bbox_pd.to_numpy()\n",
    "        self.train_bbox = {}\n",
    "        self.idx2file = {}\n",
    "        self.file2idx = {}\n",
    "        i = 0\n",
    "        for d in self.train_bbox_np:\n",
    "            if d[0] not in self.train_bbox:\n",
    "                self.train_bbox.update({d[0]:[d[1:]]})\n",
    "                self.idx2file.update({i:d[0]})\n",
    "                self.file2idx.update({d[0]:i})\n",
    "                i += 1\n",
    "            else:\n",
    "                self.train_bbox[d[0]].append(d[1:])\n",
    "        self.train_bbox = {d:np.array(self.train_bbox[d],dtype = np.float32) for d in self.train_bbox}\n",
    "        # 读取数据到内存\n",
    "        for filename in tqdm(self.train_imagefile,desc = 'Reading train data'):\n",
    "            img = Image.open(path + 'training_images/' + filename)\n",
    "            self.train_img.append([filename,img])\n",
    "            if filename not in self.train_bbox:\n",
    "                self.train_bbox.update({filename:[]})\n",
    "                self.idx2file.update({i:filename})\n",
    "                self.file2idx.update({filename:i})\n",
    "                i += 1\n",
    "                \n",
    "        for filename in tqdm(self.test_imagefile,desc = 'Reading test data'):\n",
    "            img = Image.open(path + 'testing_images/' + filename)\n",
    "            self.test_img.append([filename,img])\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(self.train_img[index][1],(Image.Image)):\n",
    "            self.train_img[index][1] = torchvision.transforms.functional.pil_to_tensor(self.train_img[index][1])/255\n",
    "        img = self.train_img[index][1]\n",
    "#         print(self.train_bbox[self.train_img[index][0]])\n",
    "        label_num = self.file2idx[self.train_img[index][0]]\n",
    "        return img, label_num\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd8d07c-8ffc-49ee-80b7-16d2de9ba422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a216bbc37714468bf17f22c018eed26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading train data:   0%|          | 0/1001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d35e8865e55461dad0dac74634c7529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading test data:   0%|          | 0/175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "car = cardset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73d86c85-bec1-42bf-afb7-2cf23915f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect(batch):\n",
    "    img,label_num = [i for i in zip(*batch)]\n",
    "    img = torch.stack(img,0)\n",
    "    label_num = torch.Tensor(label_num)\n",
    "    return img,label_num\n",
    "car_dataloader = torch.utils.data.DataLoader(car, batch_size = 8, shuffle = True,collate_fn = collect,drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0db4d875-f202-477f-8455-b389ac71d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myiter = tqdm(car_dataloader,colour = '#0066FF')\n",
    "# myiter.set_description_str('car dataloader')\n",
    "# for x,y in myiter:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a5b043e-8397-441a-90cc-3b032f6673d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTarget(x,y):\n",
    "    target = []\n",
    "    for i in y:\n",
    "        t = car.train_bbox[car.idx2file[int(i)]]\n",
    "        shape = len(t)\n",
    "        label = 1\n",
    "        if len(t) == 0:\n",
    "            t = [[0,0,x.shape[-1]-1,x.shape[-2]-1]]\n",
    "            shape = 1\n",
    "            label = 0\n",
    "        target.append({'bboxes':torch.Tensor(t).cuda(device), 'classes': torch.from_numpy(np.zeros(shape, dtype = np.int64) + label).cuda(device)})\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f296963-58fb-426a-a447-b67d88a942db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = getTarget(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ae236-2679-4cfa-b891-5d65ebfc23ba",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a8547ca-a211-4abf-97f1-7944c5f14b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centerNet = CenterNet(2)\n",
    "centerNet.to(device)\n",
    "centerNet.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa54fc6b-1eda-4ef6-98ab-da46ba2ddd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0131d115-dd8d-4aac-b859-91acd24ed936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result, losses = centerNet(x,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45453b25-8ad6-4732-9693-284dff1e2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "centerNet = torch.load('model/centerNet2.pt')\n",
    "centerNet.to(device)\n",
    "optimizer = optim.Adam(centerNet.parameters(),5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a97c25c-08c8-483f-b31e-182a55749a44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b4076e5cc4465aa7baf02bd2845200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da4cd0c94154325b1638a87fb88a581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a71957ae056f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'point_focal_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'offset_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mall_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         myiter.set_postfix(epoch = epoch,loss = float(loss),focal_loss = float(losses['point_focal_loss']),\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "centerNet.train()\n",
    "centerNet.mode = 'train'\n",
    "min_loss = 1e9\n",
    "for epoch in trange(70):\n",
    "    myiter = tqdm(car_dataloader,colour = '#0066FF')\n",
    "    myiter.set_description_str('car dataloader')\n",
    "    all_loss = 0\n",
    "    for x,y in myiter:\n",
    "        x = x.cuda(device)\n",
    "        target = getTarget(x,y)\n",
    "        result, losses = centerNet(x,target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = losses['point_focal_loss'] + 0.1*losses['size_loss'] + losses['offset_loss']\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        all_loss += float(loss)\n",
    "        myiter.set_postfix(epoch = epoch,loss = float(loss),focal_loss = float(losses['point_focal_loss']),\n",
    "                           size_loss = float(losses['size_loss']),\n",
    "                           offset_loss = float(losses['offset_loss']),all_loss = all_loss)\n",
    "        \n",
    "        \n",
    "    if all_loss < min_loss:\n",
    "        min_loss = all_loss\n",
    "        torch.save(centerNet, 'model/centerNet2.pt')\n",
    "        plt.imshow(losses['heatmap'][0][1].detach().cpu())\n",
    "        plt.show()\n",
    "        plt.imshow(losses['gt_hm'][0][1].detach().cpu())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f4535ff-9740-46e3-b3a9-c38f401008c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class focal_loss(nn.Module):\n",
    "    def __init__(self, alpha = 2, beta = 4, reduction = 'sum', N = 1):\n",
    "        super(focal_loss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.reduction = 'sum'\n",
    "        self.N = N\n",
    "        \n",
    "    def forward(self, pred_hm, gt_hm):\n",
    "        focalLoss = 0\n",
    "        pred_hm = torch.clamp(pred_hm, 1e-6, 1-1e-6)\n",
    "        pos_idx = (gt_hm == 1)\n",
    "        neg_idx = (gt_hm != 1)\n",
    "        # positive focal loss\n",
    "        focalLoss += torch.sum((1 - pred_hm[pos_idx]).pow(self.alpha)*torch.log(pred_hm[pos_idx]))\n",
    "        # negative\n",
    "        focalLoss += torch.sum((1 - gt_hm[neg_idx]).pow(self.beta)*pred_hm[neg_idx].pow(self.alpha)*torch.log(1 - pred_hm[neg_idx]))\n",
    "        if self.reduction == 'sum':\n",
    "            return -focalLoss\n",
    "        else:\n",
    "            return -focalLoss/self.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e455efef-a08d-4153-826a-f6e4db95ed9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bboxes': tensor([[  0.,   0., 675., 379.]], device='cuda:4'),\n",
       "  'classes': tensor([0], device='cuda:4')},\n",
       " {'bboxes': tensor([[  0.,   0., 675., 379.]], device='cuda:4'),\n",
       "  'classes': tensor([0], device='cuda:4')},\n",
       " {'bboxes': tensor([[  0.,   0., 675., 379.]], device='cuda:4'),\n",
       "  'classes': tensor([0], device='cuda:4')},\n",
       " {'bboxes': tensor([[  0.0000, 183.6116,  86.5789, 246.7005],\n",
       "          [185.3864, 178.7210, 305.2272, 236.9192],\n",
       "          [548.8220, 181.1664, 676.0000, 244.0412]], device='cuda:4'),\n",
       "  'classes': tensor([1, 1, 1], device='cuda:4')},\n",
       " {'bboxes': tensor([[207.3980, 190.9476, 237.7250, 212.9553]], device='cuda:4'),\n",
       "  'classes': tensor([1], device='cuda:4')},\n",
       " {'bboxes': tensor([[  0.,   0., 675., 379.]], device='cuda:4'),\n",
       "  'classes': tensor([0], device='cuda:4')},\n",
       " {'bboxes': tensor([[  0.,   0., 675., 379.]], device='cuda:4'),\n",
       "  'classes': tensor([0], device='cuda:4')},\n",
       " {'bboxes': tensor([[  0.,   0., 675., 379.]], device='cuda:4'),\n",
       "  'classes': tensor([0], device='cuda:4')}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = iter(car_dataloader).next()\n",
    "x = x.cuda(device)\n",
    "target = getTarget(x,y)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b67cf0b-0617-44ea-a242-29ec91f9a8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7304163a-4e11-4242-9a85-6f33396caa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "centerNet = CenterNet(2)\n",
    "centerNet.to(device)\n",
    "centerNet.mode\n",
    "x = x[3:4].cuda(device)\n",
    "target = getTarget(x,y[3:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "747c72ba-71c8-45e5-9dc4-5a25d6e533cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bboxes': tensor([[  0.0000, 183.6116,  86.5789, 246.7005],\n",
       "          [185.3864, 178.7210, 305.2272, 236.9192],\n",
       "          [548.8220, 181.1664, 676.0000, 244.0412]], device='cuda:4'),\n",
       "  'classes': tensor([1, 1, 1], device='cuda:4')}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4234ea88-9354-46b4-9ee5-ddf505444ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = focal_loss(2,4,reduction='mean',N = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dff7fabb-56e0-4c55-9329-50bad137f257",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(centerNet.parameters(),5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "931f5fc9-6a21-437c-a6c7-f69d3439f8b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pred_sz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f282e420a052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred_sz'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'pred_sz'"
     ]
    }
   ],
   "source": [
    "losses['pred_sz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcf5d8aa-f26c-4a88-87ae-8b0368cc3788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(250.0818, device='cuda:4', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses['size_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "798cf946-c74f-455d-97ed-aa20977d9d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.0546, device='cuda:4', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    result, losses = centerNet(x,target)\n",
    "#     pred_hm = losses['heatmap']\n",
    "#     gt_hm = losses['gt_hm']\n",
    "#     pred_sz = losses['pred_sz']\n",
    "#     gt_sz = losses['gt_sz']\n",
    "#     loss = fl(pred_hm, gt_hm)\n",
    "\n",
    "#     loss = F.mse_loss(pred_hm,gt_hm)\n",
    "    loss = losses['size_loss']\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss)\n",
    "# print(pred_sz)\n",
    "# print(gt_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc5f911-2c8a-44af-9b60-c95fecf7e24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[5]['scores'].argmax(),result[5]['scores'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7774316b-3e56-4552-93bc-be30eb575256",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[5]['bboxes'][result[5]['scores']>0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b263c-eb82-48c8-bc08-b4910c4ddb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838357b1-8fee-4ad9-ae9d-a466ea7a1521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8556fc7c-9e95-4f77-bcc9-2631fb442333",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(losses['heatmap'][5][1].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07850c5-77a8-4139-b29b-eb5f1e653517",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(losses['gt_hm'][5][1].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24502308-fc01-482a-9a92-d1104fd50b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963ed6d-b17c-4bad-9c35-435292888aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd43b4-cb3d-4dc0-9c54-fea1db763053",
   "metadata": {},
   "outputs": [],
   "source": [
    "centerNet.eval()\n",
    "centerNet.mode = 'test'\n",
    "y,l = centerNet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b1f34d-c9af-49e6-9d62-cddb6aea6598",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[1]['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80946072-4e50-44ff-ab8e-6ed5ead55ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[2]['scores'].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a5775-11c5-4cb1-9262-496e8882c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[2]['scores'][y[2]['scores'].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f89c5c6-968b-4574-926d-e3c836c9eed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[2]['bboxes'][1764]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee70dd1-95c8-4528-ac5f-739db48bb61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662d7cb5-b050-4543-a8f8-ecf088704a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c98b6bf-e946-4b8f-9df3-2c5b61b8f23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ac662a-caa2-49dd-b3a3-5b3faee8e5d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result[0]['bboxes'][:,[1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e9513f-471b-419a-805a-88ab01dda83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(losses['heatmap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc41ed1-c0a8-4f71-b2c3-a09d3c09dbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f018e28-d653-4b36-bda1-831c72177451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee4e50-fa9a-4195-905a-761010ad2896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
